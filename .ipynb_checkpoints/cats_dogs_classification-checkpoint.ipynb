{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats and dogs classification using pretrained ResNet50 CNN\n",
    "- Dataset information: **OXFORD-IIIT PET Dataset**\n",
    "- Model in this notebook is trained on **37 category pet dataset(cats and dogs) with roughly 200 images for each class**. The images have a large variations in scale, pose and lighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Input, Flatten\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labels into a pandas dataframe\n",
    "path_labels = 'pet_labels\\list.txt'     \n",
    "path_images = 'pet_images'   \n",
    "\n",
    "df_labels = pd.read_csv(path_labels, skiprows = 6, header = None, sep = ' ')\n",
    "df_labels.columns = ['Image', 'Class_ID', 'Species', 'Breed_ID']\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of examples in each class\n",
    "df_labels.Class_ID.value_counts().plot(kind = 'bar', title = 'Number of examples in each class', figsize = (12, 6),\n",
    "                                      xlabel = 'Class_ID', ylabel = 'Number of examples');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each class has almost equal number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the labels dataframe\n",
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of images\n",
    "len(os.listdir(path_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Number of images and labels are not equal**. Proper mapping of images to labels is required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and reshape all images to size (300, 300)\n",
    "- Store images along with their name in a dictionary for mapping them with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = (300, 300)   # target size of images\n",
    "\n",
    "img_no_labels = {}   # store images without labels\n",
    "images = {}          # store images with labels \n",
    "\n",
    "for img in os.listdir(path_images):\n",
    "    img_name = img.split('.')[0]   # extract name of the image\n",
    "    img = cv2.imread(os.path.join(path_images, img))   \n",
    "    \n",
    "    # OpenCV didn't read some images\n",
    "    if img is not None:\n",
    "        # Check the image name in labels dataframe\n",
    "        if img_name in df_labels.Image.values:\n",
    "            images[img_name] = cv2.resize(img, size)\n",
    "        else:\n",
    "            img_no_labels[img_name] = cv2.resize(img, size)\n",
    "    else:\n",
    "        print(img_name)   # images not read by imread function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of images in each dictionary\n",
    "print('Number of images with labels: ', len(images))\n",
    "print('Number of images without labels: ', len(img_no_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new dataframe using keys of the images dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_df = pd.Series(list(images.keys())).to_frame()\n",
    "keys_df.columns = ['Image']\n",
    "keys_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the labels dataframe with the keys dataframe on Image column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(keys_df, df_labels, on = 'Image', how = 'inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the resulting dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mapping of images with their correct labels is completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images into numpy array\n",
    "img = np.array(list(images.values())) \n",
    "# free the dictionary memory\n",
    "images.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display few random images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 10))\n",
    "columns = 4; rows = 4\n",
    "\n",
    "# sample random indices of images\n",
    "index = np.random.randint(0, len(img), size = 16)\n",
    "\n",
    "for i in range(0, columns * rows):\n",
    "    fig.add_subplot(rows, columns, i + 1)\n",
    "    plt.imshow(img[index[i]])\n",
    "    plt.title(str(df.Image.iloc[index[i]]))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout(w_pad = 0.1, h_pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(img, df.Class_ID.values, test_size = 0.2, random_state = 42, \n",
    "                                                  stratify = df.Class_ID.values)\n",
    "\n",
    "print('Train_x shape: ', train_x.shape)\n",
    "print('Test_x shape: ', val_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the labels for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels range from (1 - 37). Make them from 0 - 36\n",
    "train_y = train_y - 1\n",
    "val_y = val_y - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the base pre-trained model\n",
    "base_model = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape = (300, 300, 3)))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# flatten the outputs \n",
    "x = Flatten()(x)\n",
    "\n",
    "# add a fully-connected layer\n",
    "x = Dense(200, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer with 37 classes\n",
    "predictions = Dense(37, activation = 'softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of training and validation labels\n",
    "train_y = to_categorical(train_y)\n",
    "val_y = to_categorical(val_y)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# check the shape of one hot encoded labels\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make last two blocks of the base_model trainable:\n",
    "\n",
    "for layer in base_model.layers[:155]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in base_model.layers[155:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "print('Last two block of the base_model are now trainable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data augmentation using image data generator\n",
    "train_Aug = ImageDataGenerator(horizontal_flip = True)\n",
    "\n",
    "# validation data augmentation\n",
    "val_Aug = ImageDataGenerator()\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) \n",
    "mean = np.array([123.68, 116.779, 103.939], dtype = \"float32\")\n",
    "train_Aug.mean = mean\n",
    "val_Aug.mean = mean\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(x = train_Aug.flow(train_x, train_y, batch_size = 64), validation_data = val_Aug.flow(val_x, val_y), \n",
    "          steps_per_epoch = len(train_x) // 64, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
